model:
  name: "meta-llama/Meta-Llama-3-8B-Instruct"
  backend: "vllm"
  vllm:
    base_url: "http://127.0.0.1:8000/v1"
    api_key: ""  # set if your vLLM endpoint requires auth
